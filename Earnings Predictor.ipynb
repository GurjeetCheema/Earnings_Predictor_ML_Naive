{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earnings Predictor\n",
    "## Using Adult Dataset CSV, Applied knowledge of the Naive Bayes Model and mathematical equations to code an analytic model for predicting earnings given a set of large set of features. Developed from scratch in python without using any libraries for Naive Bayes Algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function should prepare the data by reading it from a file and converting it into a useful format for training and testing and implement 90-10 splitting as specified in the project description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "#headers\n",
    "numeric = [\"age\", \"education num\", \"hours per week\"]\n",
    "category = [\"work class\", \"education\", \"marital status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native country (region)\"]\n",
    "classifers = [\" <=50K\", \" >50K\"]\n",
    "\n",
    "#reads files and splits it\n",
    "def preprocess(filename):    \n",
    "    df = pd.read_csv(filename)\n",
    "    df.head()\n",
    "    \n",
    "    #removes rows with question marks in them\n",
    "    for num in numeric:\n",
    "        df = df[df[num] != ' ?']\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.1, shuffle = False)\n",
    "    \n",
    "    return df_train, df_test, df\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function should calculat prior probabilities and likelihoods (conditional probabilities) from the training data and using to build a naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#slpits into the to labels\n",
    "def splitClassifers(df, lis):\n",
    "    #creates 2 datafreams for both classifiers\n",
    "    d0 = pd.DataFrame(columns=lis)\n",
    "    d1 = pd.DataFrame(columns=lis)\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    \n",
    "    #splits into correct labels by looping through\n",
    "    #dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        if row[\"label\"] == classifers[0]:\n",
    "            d0 = d0.append(row[lis])\n",
    "            count0 += 1\n",
    "            \n",
    "        if row[\"label\"] == classifers[1]:\n",
    "            d1 = d1.append(row[lis])\n",
    "            count1 += 1\n",
    "    \n",
    "    #returns dataframes and size of data frames\n",
    "    return d0, d1, count0, count1\n",
    "\n",
    "\n",
    "#gets the nominal probability using naive bayes\n",
    "def getProbNominal(c0,c1,prior0,prior1,cCount0,cCount1, df_train):\n",
    "        \n",
    "        #creates a dictionary within a dictionary\n",
    "        #first dimension stores all headers\n",
    "        #second store all possible values and their probabilities\n",
    "        probNominal0 = {}\n",
    "        probNominal1 = {}\n",
    "        \n",
    "        \n",
    "        #loops and assigns values in the right place\n",
    "        for cat in category:\n",
    "            catlis = []\n",
    "            for index, row in df_train.iterrows():\n",
    "                if row[cat] not in catlis:\n",
    "                    catlis.append(row[cat])\n",
    "                \n",
    "\n",
    "            probNominal0[cat] = {}\n",
    "            probNominal1[cat] = {}\n",
    "            #calculates probabilitlies for each item within category\n",
    "            for item in catlis:\n",
    "                rec0 = 0\n",
    "                rec1 = 0\n",
    "                \n",
    "\n",
    "                if item in c0[cat].values:\n",
    "                    rec0 = c0[cat].value_counts()[item]\n",
    "                    \n",
    "                if item in c1[cat].values:\n",
    "                    rec1 = c1[cat].value_counts()[item]\n",
    "                    \n",
    "                probNominal0[cat][item] = (1 + rec0)/(cCount0 + len(catlis))\n",
    "                probNominal1[cat][item] = (1 + rec1)/(cCount1 + len(catlis))\n",
    "            \n",
    "        \n",
    "        #returns probability for both classifiers in the form of the\n",
    "        #2d dictionary\n",
    "        return probNominal0, probNominal1\n",
    "    \n",
    "\n",
    "#calculates gussian probability\n",
    "def getProbNumericGuassian(value, category, nPrior0, nPrior1, n0, n1):\n",
    "    mean0 = n0[category].mean()\n",
    "    std0 = n0[category].std()\n",
    "    mean1 = n1[category].mean()\n",
    "    std1 = n1[category].std()\n",
    "    \n",
    "    prob0 = (1/ (np.sqrt(2 * np.pi) * std0))* np.exp(-((value-mean0)**2 / (2 * std0 *2)))\n",
    "    prob1 = (1/ (np.sqrt(2 * np.pi) * std1))* np.exp(-((value-mean1)**2 / (2 * std1 *2)))\n",
    "    \n",
    "    return prob0, prob1\n",
    "\n",
    "#trains data by geting pirors and calculating all nessasary probabilities\n",
    "def train(df_train):\n",
    "    \n",
    "    \n",
    "    c0, c1, cCount0, cCount1 =splitClassifers(df_train, category)\n",
    "    n0, n1, nCount0, nCount1 =splitClassifers(df_train, numeric)\n",
    "    \n",
    "    \n",
    "    cPrior0 = cCount0/(cCount0+cCount1)\n",
    "    cPrior1 = cCount1/(cCount1+cCount0)\n",
    "    nPrior0 = nCount0/(nCount0+nCount1)\n",
    "    nPrior1 = nCount1/(nCount1+nCount0)\n",
    "    \n",
    "\n",
    "    probC0, probC1 = getProbNominal(c0,c1,cPrior0,cPrior1,cCount0,cCount1, df_train)\n",
    "    \n",
    "    return probC0, probC1, cPrior0, cPrior1, nPrior0, nPrior1, n0, n1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function should predict classes for new items in the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(probC0, probC1, df_test, cPrior0, cPrior1, nPrior0, nPrior1, n0, n1):\n",
    "    \n",
    "    \n",
    "    #lists saving predicted values and their probabilites\n",
    "    predictedValues = []\n",
    "    logprobabilities = []\n",
    "    \n",
    "    for index, row in df_test.iterrows():\n",
    "        \n",
    "        \n",
    "        probnom0 = cPrior0\n",
    "        probnom1 = cPrior1\n",
    "        totalProb0 = 0\n",
    "        totalProb1 = 0\n",
    "        \n",
    "        #caculates total probability for each test cases category\n",
    "        for nominal in category:\n",
    "                probnom0 *= probC0[nominal][row[nominal]]    \n",
    "                probnom1 *= probC1[nominal][row[nominal]]\n",
    "        \n",
    "        probnum0 = nPrior0\n",
    "        probnum1 = nPrior1\n",
    "        \n",
    "        #caculates total probability for each test cases numeric category\n",
    "        for numCat in numeric:\n",
    "            \n",
    "            p0, p1 = getProbNumericGuassian(row[numCat], numCat, nPrior0, nPrior1, n0, n1)\n",
    "            \n",
    "            probnum0 *= p0\n",
    "            probnum1 *= p1\n",
    "            \n",
    "        totalProb0 = probnum0 * probnom0\n",
    "        totalProb1 = probnum1 * probnom1\n",
    "        \n",
    "        #finds higher probability between both classifiers and saves accordingly\n",
    "        if totalProb0 > totalProb1:\n",
    "\n",
    "            predictedValues.append(classifers[0])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            predictedValues.append(classifers[1])\n",
    "        \n",
    "        logprobabilities.append([np.log(totalProb0),np.log(totalProb1)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predictedValues, logprobabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function should evaliate the prediction performance by comparing your modelâ€™s class outputs to ground truth labels, return and output accuracy, confusion matrix and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#prints relevant values\n",
    "def evaluate(df_test, predictedValues):\n",
    "    \n",
    "    #gets accuracy score\n",
    "    print(\"accuracy score: \",accuracy_score(df_test['label'], predictedValues))\n",
    "    print()\n",
    "    \n",
    "    #gets confusion matrix\n",
    "    print(\"confusion matrix: \")\n",
    "    print(confusion_matrix(df_test['label'], predictedValues))\n",
    "    print()\n",
    "    \n",
    "    #gets all values in confusion matrix, will be useful later\n",
    "    tp, fp, fn, tn = confusion_matrix(df_test['label'], predictedValues).ravel()\n",
    "    \n",
    "    #calculates fscore\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(\"F score: \",f1)\n",
    "    print()\n",
    "    return tp, fp, fn, tn "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell acts like a \"main\" function calling all functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.86\n",
      "\n",
      "confusion matrix: \n",
      "[[69  8]\n",
      " [ 6 17]]\n",
      "\n",
      "F score:  0.9078947368421053\n",
      "\n",
      "\n",
      "\n",
      "Predicted class log-probabilities for instance N-3:  [-23.34177986125614, -21.359906228009308]\n",
      "Predicted class ID for instance N-3:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-2:  [-34.67407731543075, -27.981720618223235]\n",
      "Predicted class ID for instance N-2:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-1:  [-17.46728258073397, -19.216525280553885]\n",
      "Predicted class ID for instance N-1:   <=50K\n"
     ]
    }
   ],
   "source": [
    "#  reads in the data and apply your NB model to the ADULT data\n",
    "df_train, df_test, df = preprocess(\"adult.csv\")\n",
    "\n",
    "\n",
    "#trans dataset and outputs probabilities for related categories\n",
    "probC0, probC1, cPrior0, cPrior1, nPrior0, nPrior1, n0, n1= train(df_train)\n",
    "\n",
    "#predicts using test data and outputs predicted values and log probabilities\n",
    "predictedValues, logporbabilites = predict(probC0, probC1, df_test, cPrior0, cPrior1, nPrior0, nPrior1, n0, n1)\n",
    "\n",
    "\n",
    "\n",
    "# Second, print the full evaluation results from the evaluate() function\n",
    "\n",
    "tp, fp, fn, tn = evaluate(df_test, predictedValues)\n",
    "\n",
    "# Third, print data statistics and model predictions, as instructed below \n",
    "# N is the total number of instances, F the total number of attributes, L the total number of labels\n",
    "# The \"class probabilities\" may be unnormalized\n",
    "# The \"predicted class ID\" must be in range (0, L)\n",
    "\n",
    "#print(\"Attribute vectors of instances [0, 1, 2]: \", [df.iloc[[0]].values.tolist(),df.iloc[[1]].values.tolist(),df.iloc[[2]].values.tolist()]) # of the first three records in adult.csv\n",
    "\n",
    "#print(\"\\nNumber of instances (N): \", len(df))\n",
    "#print(\"Number of attributes (F): \", len(df.columns))\n",
    "#print(\"Number of labels (L): \", len(pd.unique(df[\"label\"])))\n",
    "\n",
    "\n",
    "# print out the prediction results of the last three instances\n",
    "print(\"\\n\\nPredicted class log-probabilities for instance N-3: \",logporbabilites[len(logporbabilites)-3] )\n",
    "print(\"Predicted class ID for instance N-3: \",predictedValues[len(predictedValues)-3] )\n",
    "print(\"\\nPredicted class log-probabilities for instance N-2: \", logporbabilites[len(logporbabilites)-2])\n",
    "print(\"Predicted class ID for instance N-2: \", predictedValues[len(predictedValues)-2])\n",
    "print(\"\\nPredicted class log-probabilities for instance N-1: \", logporbabilites[len(logporbabilites)-1])\n",
    "print(\"Predicted class ID for instance N-1: \", predictedValues[len(predictedValues)-1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
